name: USCIS Case Checker

on:
  workflow_dispatch:
  schedule:
    # Corre cada hora (ajústalo a tu gusto)
    - cron: "0 * * * *"

concurrency:
  group: uscis-checker
  cancel-in-progress: false

jobs:
  check:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20.x"
          # No activamos cache de npm si no hay package-lock.json
          # cache: "npm"

      - name: Install dependencies
        run: |
          if [ -f package-lock.json ]; then
            npm ci --no-audit --no-fund
          else
            npm i --no-audit --no-fund
          fi

      - name: Install Playwright (Chrome + system deps)
        run: npx playwright install --with-deps chrome

      - name: Ensure Google Chrome present
        run: |
          google-chrome --version || true
          node -e "console.log('Playwright version:', require('playwright/package.json').version)"

      # ===== PROXY ES OBLIGATORIO PARA EVITAR CLOUDFLARE EN RUNNERS PÚBLICOS =====
      - name: Validate required secrets (API & Proxy)
        run: |
          MISSING=0
          [ -z "${{ secrets.API_BASE }}" ] && echo "::error::Missing secret API_BASE" && MISSING=1
          [ -z "${{ secrets.API_TOKEN }}" ] && echo "::error::Missing secret API_TOKEN" && MISSING=1
          [ -z "${{ secrets.PROXY_SERVER }}" ] && echo "::error::Missing secret PROXY_SERVER (e.g. http://host:port)" && MISSING=1
          [ -z "${{ secrets.PROXY_USERNAME }}" ] && echo "::error::Missing secret PROXY_USERNAME" && MISSING=1
          [ -z "${{ secrets.PROXY_PASSWORD }}" ] && echo "::error::Missing secret PROXY_PASSWORD" && MISSING=1
          if [ "$MISSING" -eq 1 ]; then
            echo "One or more required secrets are missing. Aborting."
            exit 1
          fi
          echo "All required secrets present."

      - name: Run scraper (Chrome headful bajo Xvfb + Proxy residencial)
        env:
          # Backend
          API_BASE: ${{ secrets.API_BASE }}
          API_TOKEN: ${{ secrets.API_TOKEN }}

          # Parámetros funcionales del worker
          LIMIT: "10"
          FORCE: "1"
          HEADFUL: "1"
          USE_CHROME: "1"
          DEBUG: "1"
          CF_WAIT_MS: "180000"   # 3 min por item; el script puede tomar este hint si lo soporta

          # Entorno más “humano”
          TZ: "America/New_York"
          LANG: "en_US.UTF-8"
          LC_ALL: "en_US.UTF-8"

          # Proxy residencial/ISP (requerido)
          PROXY_SERVER: ${{ secrets.PROXY_SERVER }}       # p.ej: http://host:port ó http://ip:port
          PROXY_USERNAME: ${{ secrets.PROXY_USERNAME }}
          PROXY_PASSWORD: ${{ secrets.PROXY_PASSWORD }}

        run: |
          echo "Starting scraper with proxy enabled."
          xvfb-run -s "-screen 0 1366x768x24" -a npm run check
